{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sklearn\n",
    "import seaborn\n",
    "metric = sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load data\n",
    "\n",
    "data = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "data.loc[data['v1'].eq('ham'),'v1'] = 1\n",
    "data.loc[data['v1'].eq('spam'),'v1'] = 0\n",
    "data['v1']=data['v1'].astype('float64')\n",
    "\n",
    "\n",
    "# Balance dataset\n",
    "n = 747\n",
    "sample_yes = data.ix[data.v1 == 1].sample(n=n, replace=False, random_state=0)\n",
    "sample_no = data.ix[data.v1 == 0].sample(n=n, replace=False, random_state=0)\n",
    "data = pd.concat([sample_yes, sample_no])\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = data[:500]\n",
    "test_data = data[500:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize the text\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data.v2)\n",
    "y_train = train_data.v1\n",
    "\n",
    "X_test = vectorizer.transform(test_data.v2)\n",
    "y_test = test_data.v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model_1 = Perceptron(max_iter=1000, tol=1e-3)\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model_3 = AdaBoostClassifier(n_estimators=3)\n",
    "model_3.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Ensemble\n",
    "\n",
    "#ensemble = RandomForestClassifier(n_estimators=10, n_jobs=-1).fit(vectorized_text, train_data.v1)\n",
    "ensemble = [model_1,model_2,model_3]\n",
    "n_models = len(ensemble)\n",
    "\n",
    "predictions = np.array([h.predict(X_train) for h in ensemble])\n",
    "# scale hij to [-1/N, 1/N]\n",
    "predictions =(predictions* 1/n_models)\n",
    "\n",
    "λ = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coeffitients\n",
    "\n",
    "w = predictions @ predictions.T\n",
    "wii = X_train.shape[0] / (n_models ** 2) + λ - 2 * predictions @ y_train\n",
    "w[np.diag_indices_from(w)] = wii\n",
    "W = {}\n",
    "for i in range(n_models):\n",
    "    for j in range(i, n_models):\n",
    "        W[(i, j)] = w[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimod\n",
    "#sampler = dimod.SimulatedAnnealingSampler()\n",
    "#response = sampler.sample_qubo(W, num_reads=100)\n",
    "#weights = list(response.first.sample.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ising model\n",
    "\n",
    "h, J, offset = dimod.qubo_to_ising(W)\n",
    "from qiskit.quantum_info import Pauli\n",
    "from qiskit.aqua import Operator\n",
    "\n",
    "num_nodes = len(w)\n",
    "pauli_list = []\n",
    "for i in range(num_nodes):\n",
    "    wp = np.zeros(num_nodes)\n",
    "    vp = np.zeros(num_nodes)\n",
    "    vp[i] = 1\n",
    "    pauli_list.append([h[i], Pauli(vp, wp)])\n",
    "    for j in range(i+1, num_nodes):\n",
    "        if w[i, j] != 0:\n",
    "            wp = np.zeros(num_nodes)\n",
    "            vp = np.zeros(num_nodes)\n",
    "            vp[i] = 1\n",
    "            vp[j] = 1\n",
    "            pauli_list.append([J[i, j], Pauli(vp, wp)])\n",
    "ising_model = Operator(paulis=pauli_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize Ising model\n",
    "\n",
    "from qiskit.aqua import get_aer_backend, QuantumInstance\n",
    "from qiskit.aqua.algorithms import QAOA\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "p = 1\n",
    "optimizer = COBYLA()\n",
    "qaoa = QAOA(ising_model, optimizer, p, operator_mode='matrix')\n",
    "backend = get_aer_backend('statevector_simulator')\n",
    "quantum_instance = QuantumInstance(backend, shots=100)\n",
    "result = qaoa.run(quantum_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, weights, X):\n",
    "\n",
    "    n_data = X.shape[0]\n",
    "    T = 0\n",
    "    y = np.zeros(n_data)\n",
    "    for i, h in enumerate(models):\n",
    "        #print('type of predict')\n",
    "        y0 = weights[i] * h.predict(X)  # prediction of weak classifier\n",
    "        y += y0\n",
    "        T += np.sum(y0)\n",
    "\n",
    "    y = np.sign(y - T / (n_data*len(models)))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimized weights of estimators\n",
    "k = np.argmin(result['eigvecs'][0])\n",
    "weights = np.zeros(num_nodes)\n",
    "for i in range(num_nodes):\n",
    "    weights[i] = k % 2\n",
    "    k >>= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized_test = vectorizer.transform(test_data.v2)\n",
    "print('accuracy (test): %5.2f'%(metric( y_test, predict(ensemble, weights, X_test))))\n",
    "print('accuracy (train): %5.2f'%(metric( y_train, predict(ensemble, weights, X_train))))\n",
    "#print('accuracy (test): %5.2f'%(metric( test_data.v1, predict(ensemble, weights, vectorized_text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
