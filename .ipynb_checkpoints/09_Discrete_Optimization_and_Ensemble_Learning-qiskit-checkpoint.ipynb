{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any learning algorithm will always have strengths and weaknesses: a single model is unlikely to fit every possible scenario. Ensembles combine multiple models to achieve higher generalization performance than any of the constituent models is capable of. How do we assemble the weak learners? We can use some sequential heuristics. For instance, given the current collection of models, we can add one more based on where that particular model performs well. Alternatively, we can look at all the correlations of the predictions between all models, and optimize for the most uncorrelated predictors. Since this latter is a global approach, it naturally maps to a quantum computer. But first, let's take a look a closer look at loss functions and regularization, two key concepts in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions and Regularization\n",
    "\n",
    "If you can solve a problem by a classical computer -- let that be a laptop or a massive GPU cluster -- there is little value in solving it by a quantum computer that costs ten million dollars. The interesting question in quantum machine learning is whether there are problems in machine learning and AI that fit quantum computers naturally, but are challenging on classical hardware. This, however, requires a good understanding of both machine learning and contemporary quantum computers.\n",
    "\n",
    "In this course, we primarily focus on the second aspect, since there is no shortage of educational material on classical machine learning. However, it is worth spending a few minutes on going through some basics.\n",
    "\n",
    "Let us take a look at the easiest possible problem: the data points split into two, easily distinguishable sets. We randomly generate this data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0308784668>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "c1 = np.random.rand(50, 2)/5\n",
    "c2 = (-0.6, 0.5) + np.random.rand(50, 2)/5\n",
    "data = np.concatenate((c1, c2))\n",
    "labels = np.array([0] * 50 + [1] *50)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.subplot(111, xticks=[], yticks=[])\n",
    "plt.scatter(data[:50, 0], data[:50, 1], color='navy')\n",
    "plt.scatter(data[50:, 0], data[50:, 1], color='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle the data set into a training set that we are going to optimize over (2/3 of the data), and a test set where we estimate our generalization performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(labels))\n",
    "np.random.shuffle(idx)\n",
    "# train on a random 2/3 and test on the remaining 1/3\n",
    "idx_train = idx[:2*len(idx)//3]\n",
    "idx_test = idx[2*len(idx)//3:]\n",
    "X_train = data[idx_train]\n",
    "X_test = data[idx_test]\n",
    "y_train = labels[idx_train]\n",
    "y_test = labels[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the package `scikit-learn` to train various machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "metric = sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a perceptron, which has a linear loss function $\\frac{1}{N}\\sum_{i=1}^N |h(x_i)-y_i)|$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  1.00\n",
      "accuracy (test):  1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model_1 = Perceptron(max_iter=1000, tol=1e-3)\n",
    "model_1.fit(X_train, y_train)\n",
    "print('accuracy (train): %5.2f'%(metric(y_train, model_1.predict(X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, model_1.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does a great job. It is a linear model, meaning its decision surface is a plane. Our dataset is separable by a plane, so let's try another linear model, but this time a support vector machine. If you eyeball our dataset, you will see that to define the separation between the two classes, actually only a few points close to the margin are relevant. These are called support vectors and support vector machines aim to find them. Its objective function measures the loss and it has a regularization term with a weight $C$. The $C$ hyperparameter controls a regularization term that penalizes the objective for the number of support vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  1.00\n",
      "accuracy (test):  1.00\n",
      "Number of support vectors: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_2 = SVC(kernel='linear', C=10)\n",
    "model_2.fit(X_train, y_train)\n",
    "print('accuracy (train): %5.2f'%(metric(y_train, model_2.predict(X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, model_2.predict(X_test))))\n",
    "print('Number of support vectors:', sum(model_2.n_support_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It picks only two datapoints out of the hundred. Let's change the hyperparameter to reduce the penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  1.00\n",
      "accuracy (test):  1.00\n",
      "Number of support vectors: 66\n"
     ]
    }
   ],
   "source": [
    "model_2 = SVC(kernel='linear', C=0.01)\n",
    "model_2.fit(X_train, y_train)\n",
    "print('accuracy (train): %5.2f'%(metric(y_train, model_2.predict(X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, model_2.predict(X_test))))\n",
    "print('Number of support vectors:', sum(model_2.n_support_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the model gets confused by using too many datapoints in the final classifier. This is one example where regularization helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods\n",
    "\n",
    "Ensembles yield better results when there is considerable diversity among the base classifiers. If diversity is sufficient, base classifiers make different errors, and a strategic combination may reduce the total error, ideally improving generalization performance. A constituent model in an ensemble is also called a base classifier or weak learner, and the composite model a strong learner.\n",
    "\n",
    "The generic procedure of ensemble methods has two steps. First, develop a set of base classifiers from the training data. Second, combine them to form the ensemble. In the simplest combination, the base learners vote, and the label prediction is based on majority. More involved methods weigh the votes of the base learners. \n",
    "\n",
    "Let us import some packages and define our figure of merit as accuracy in a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.000793Z",
     "start_time": "2018-11-19T20:10:17.128450Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "%matplotlib inline\n",
    "\n",
    "metric = sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a random dataset of two classes that form concentric circles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.174692Z",
     "start_time": "2018-11-19T20:10:18.003641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0301ee9240>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "data, labels = sklearn.datasets.make_circles()\n",
    "idx = np.arange(len(labels))\n",
    "np.random.shuffle(idx)\n",
    "# train on a random 2/3 and test on the remaining 1/3\n",
    "idx_train = idx[:2*len(idx)//3]\n",
    "idx_test = idx[2*len(idx)//3:]\n",
    "X_train = data[idx_train]\n",
    "X_test = data[idx_test]\n",
    "\n",
    "y_train = 2 * labels[idx_train] - 1  # binary -> spin\n",
    "y_test = 2 * labels[idx_test] - 1\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "normalizer = sklearn.preprocessing.Normalizer()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_test = normalizer.fit_transform(X_test)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.subplot(111, xticks=[], yticks=[])\n",
    "plt.scatter(data[labels == 0, 0], data[labels == 0, 1], color='navy')\n",
    "plt.scatter(data[labels == 1, 0], data[labels == 1, 1], color='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.226327Z",
     "start_time": "2018-11-19T20:10:18.177561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  0.44\n",
      "accuracy (test):  0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model_1 = Perceptron(max_iter=1000, tol=1e-3)\n",
    "model_1.fit(X_train, y_train)\n",
    "print('accuracy (train): %5.2f'%(metric(y_train, model_1.predict(X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, model_1.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since its decision surface is linear, we get a poor accuracy. Would a support vector machine with a nonlinear kernel fare better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.244639Z",
     "start_time": "2018-11-19T20:10:18.230025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  0.64\n",
      "accuracy (test):  0.24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_2 = SVC(kernel='rbf', gamma='auto')\n",
    "model_2.fit(X_train, y_train)\n",
    "print('accuracy (train): %5.2f'%(metric(y_train, model_2.predict(X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, model_2.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs better on the training set, but at the cost of extremely poor generalization. \n",
    "\n",
    "Boosting is an ensemble method that explicitly seeks models that complement one another. The variation between boosting algorithms is how they combine weak learners. Adaptive boosting (AdaBoost) is a popular method that combines the weak learners in a sequential manner based on their individual accuracies. It has a convex objective function that does not penalize for complexity: it is likely to include all available weak learners in the final ensemble. Let's train AdaBoost with a few weak learners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.314089Z",
     "start_time": "2018-11-19T20:10:18.248869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  0.65\n",
      "accuracy (test):  0.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model_3 = AdaBoostClassifier(n_estimators=3)\n",
    "model_3.fit(X_train, y_train)\n",
    "print('accuracy (train): %5.2f'%(metric(y_train, model_3.predict(X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, model_3.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its performance is marginally better than that of the SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QBoost\n",
    "\n",
    "The idea of Qboost is that optimization on a quantum computer is not constrained to convex objective functions, therefore we can add arbitrary penalty terms and rephrase our objective [[1](#1)]. Qboost solves the following problem:\n",
    "\n",
    "$$\n",
    "\\mathrm{argmin}_{w} \\left(\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\sum_{k=1}^{K}w_kh_k(x_i)-\n",
    "y_i\\right)^2+\\lambda\\|w\\|_0\\right),\n",
    "$$\n",
    "\n",
    "where $h_k(x_i)$ is the prediction of the weak learner $k$ for a training instance $k$. The weights in this formulation are binary, so this objective function already maps to an Ising model. The regularization in the $l_0$ norm ensures sparsity, and it is not the kind of regularization we would consider classically: it is hard to optimize with this term on a digital computer.\n",
    "\n",
    "Let us expand the quadratic part of the objective:\n",
    "\n",
    "$$\n",
    "\\mathrm{argmin}_{w} \\left(\\frac{1}{N}\\sum_{i=1}^{N}\n",
    "\\left( \\left(\\sum_{k=1}^{K} w_k h_k(x_i)\\right)^{2} -\n",
    "2\\sum_{k=1}^{K} w_k h_k(\\mathbf{x}_i)y_i + y_i^{2}\\right) + \\lambda \\|w\\|_{0}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "Since $y_i^{2}$ is just a constant offset, the optimization reduces to\n",
    "\n",
    "$$\n",
    "\\mathrm{argmin}_{w} \\left(\n",
    "\\frac{1}{N}\\sum_{k=1}^{K}\\sum_{l=1}^{K} w_k w_l\n",
    "\\left(\\sum_{i=1}^{N}h_k(x_i)h_l(x_i)\\right) - \n",
    "\\frac{2}{N}\\sum_{k=1}^{K}w_k\\sum_{i=1}^{N} h_k(x_i)y_i +\n",
    "\\lambda \\|w\\|_{0} \\right).\n",
    "$$\n",
    "\n",
    "This form shows that we consider all correlations between the predictions of the weak learners: there is a summation of $h_k(x_i)h_l(x_i)$. Since this term has a positive sign, we penalize for correlations. On the other hand, the correlation with the true label, $h_k(x_i)y_i$, has a negative sign. The regularization term remains unchanged.\n",
    "\n",
    "Let us consider all three models from the previous section as weak learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.320974Z",
     "start_time": "2018-11-19T20:10:18.316633Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [model_1, model_2, model_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate their predictions and set $\\lambda$ to 1. The predictions are scaled to reflecting the averaging in the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.354723Z",
     "start_time": "2018-11-19T20:10:18.323802Z"
    }
   },
   "outputs": [],
   "source": [
    "n_models = len(models)\n",
    "\n",
    "predictions = np.array([h.predict(X_train) for h in models], dtype=np.float64)\n",
    "# scale hij to [-1/N, 1/N]\n",
    "predictions *= 1/n_models\n",
    "\n",
    "λ = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the quadratic binary optimization of the objective function as we expanded above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.375760Z",
     "start_time": "2018-11-19T20:10:18.357248Z"
    }
   },
   "outputs": [],
   "source": [
    "w = predictions @ predictions.T\n",
    "wii = len(X_train) / (n_models ** 2) + λ - 2 * predictions @ y_train\n",
    "w[np.diag_indices_from(w)] = wii\n",
    "W = {}\n",
    "for i in range(n_models):\n",
    "    for j in range(i, n_models):\n",
    "        W[(i, j)] = w[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve the quadratic binary optimization with simulated annealing and read out the optimal weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dimod\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/c1/e40235dac232c23ef3dd6aa70771cf544248b58883795d797781feb506d6/dimod-0.8.15-cp37-cp37m-manylinux1_x86_64.whl (829kB)\n",
      "\u001b[K     |████████████████████████████████| 839kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.15.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from dimod) (1.16.4)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from dimod) (1.12.0)\n",
      "Collecting jsonschema<3.0.0,>=2.6.0 (from dimod)\n",
      "  Using cached https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: jupyterlab-server 1.0.0 has requirement jsonschema>=3.0.1, but you'll have jsonschema 2.6.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jsonschema, dimod\n",
      "  Found existing installation: jsonschema 3.0.1\n",
      "    Uninstalling jsonschema-3.0.1:\n",
      "      Successfully uninstalled jsonschema-3.0.1\n",
      "Successfully installed dimod-0.8.15 jsonschema-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dimod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.703378Z",
     "start_time": "2018-11-19T20:10:18.378217Z"
    }
   },
   "outputs": [],
   "source": [
    "import dimod\n",
    "sampler = dimod.SimulatedAnnealingSampler()\n",
    "response = sampler.sample_qubo(W, num_reads=10)\n",
    "weights = list(response.first.sample.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a prediction function to help with measuring accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.715360Z",
     "start_time": "2018-11-19T20:10:18.705496Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(models, weights, X):\n",
    "\n",
    "    n_data = len(X)\n",
    "    T = 0\n",
    "    y = np.zeros(n_data)\n",
    "    for i, h in enumerate(models):\n",
    "        y0 = weights[i] * h.predict(X)  # prediction of weak classifier\n",
    "        y += y0\n",
    "        T += np.sum(y0)\n",
    "\n",
    "    y = np.sign(y - T / (n_data*len(models)))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.734604Z",
     "start_time": "2018-11-19T20:10:18.719931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  0.65\n",
      "accuracy (test):  0.29\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (train): %5.2f'%(metric(y_train, predict(models, weights, X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, predict(models, weights, X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy co-incides with our strongest weak learner's, the AdaBoost model. Looking at the optimal weights, this is apparent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.751765Z",
     "start_time": "2018-11-19T20:10:18.736771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only AdaBoost made it to the final ensemble. The first two models perform poorly and their predictions are correlated. Yet, if you remove regularization by setting $\\lambda=0$ above, the second model also enters the ensemble, decreasing overall performance. This shows that the regularization is in fact important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving by QAOA\n",
    "\n",
    "Since eventually our problem is just an Ising model, we can also solve it on a gate-model quantum computer by QAOA. Let us explicitly map the binary optimization to the Ising model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:18.765328Z",
     "start_time": "2018-11-19T20:10:18.754605Z"
    }
   },
   "outputs": [],
   "source": [
    "h, J, offset = dimod.qubo_to_ising(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in /home/vasilis/anaconda3/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: qiskit-aer==0.3.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit) (0.3.0)\n",
      "Requirement already satisfied: qiskit-aqua==0.6.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit) (0.6.0)\n",
      "Requirement already satisfied: qiskit-ibmq-provider==0.3.2 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit) (0.3.2)\n",
      "Requirement already satisfied: qiskit-terra==0.9.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit) (0.9.0)\n",
      "Requirement already satisfied: qiskit-ignis==0.2.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aer==0.3.0->qiskit) (1.16.4)\n",
      "Requirement already satisfied: jsonschema<2.7,>=2.6 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (2.6.0)\n",
      "Requirement already satisfied: cvxopt in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (1.2.3)\n",
      "Requirement already satisfied: pyscf; sys_platform != \"win32\" in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (1.6.3)\n",
      "Requirement already satisfied: fastdtw in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (0.3.2)\n",
      "Requirement already satisfied: h5py in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (2.9.0)\n",
      "Requirement already satisfied: sympy>=1.3 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (1.4)\n",
      "Requirement already satisfied: dlx in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (1.0.4)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (41.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (0.21.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (2.3)\n",
      "Requirement already satisfied: docplex in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (2.10.155)\n",
      "Requirement already satisfied: psutil>=5 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (5.6.3)\n",
      "Requirement already satisfied: quandl in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (3.4.8)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-aqua==0.6.0->qiskit) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio==1.0.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-ibmq-provider==0.3.2->qiskit) (1.0.0)\n",
      "Requirement already satisfied: requests-ntlm>=1.1.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-ibmq-provider==0.3.2->qiskit) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.19 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-ibmq-provider==0.3.2->qiskit) (2.22.0)\n",
      "Requirement already satisfied: websockets<8,>=7 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-ibmq-provider==0.3.2->qiskit) (7.0)\n",
      "Requirement already satisfied: marshmallow<3,>=2.17.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-terra==0.9.0->qiskit) (2.20.4)\n",
      "Requirement already satisfied: marshmallow-polyfield<4,>=3.2 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-terra==0.9.0->qiskit) (3.2)\n",
      "Requirement already satisfied: ply>=3.10 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from qiskit-terra==0.9.0->qiskit) (3.11)\n",
      "Requirement already satisfied: six in /home/vasilis/anaconda3/lib/python3.7/site-packages (from h5py->qiskit-aqua==0.6.0->qiskit) (1.12.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from sympy>=1.3->qiskit-aqua==0.6.0->qiskit) (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.20.0->qiskit-aqua==0.6.0->qiskit) (0.13.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from networkx>=2.2->qiskit-aqua==0.6.0->qiskit) (4.4.0)\n",
      "Requirement already satisfied: docloud>=1.0.369 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from docplex->qiskit-aqua==0.6.0->qiskit) (1.0.375)\n",
      "Requirement already satisfied: pandas>=0.14 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from quandl->qiskit-aqua==0.6.0->qiskit) (0.24.2)\n",
      "Requirement already satisfied: pyOpenSSL in /home/vasilis/anaconda3/lib/python3.7/site-packages (from quandl->qiskit-aqua==0.6.0->qiskit) (19.0.0)\n",
      "Requirement already satisfied: inflection>=0.3.1 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from quandl->qiskit-aqua==0.6.0->qiskit) (0.3.1)\n",
      "Requirement already satisfied: more-itertools<=5.0.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from quandl->qiskit-aqua==0.6.0->qiskit) (5.0.0)\n",
      "Requirement already satisfied: python-dateutil in /home/vasilis/anaconda3/lib/python3.7/site-packages (from quandl->qiskit-aqua==0.6.0->qiskit) (2.8.0)\n",
      "Requirement already satisfied: pyasn1 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from quandl->qiskit-aqua==0.6.0->qiskit) (0.4.7)\n",
      "Requirement already satisfied: ndg-httpsclient in /home/vasilis/anaconda3/lib/python3.7/site-packages (from quandl->qiskit-aqua==0.6.0->qiskit) (0.5.1)\n",
      "Requirement already satisfied: cryptography>=1.3 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.3.2->qiskit) (2.7)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.3.2->qiskit) (1.4.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.3.2->qiskit) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.3.2->qiskit) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.3.2->qiskit) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.3.2->qiskit) (2019.6.16)\n",
      "Requirement already satisfied: pytz>=2011k in /home/vasilis/anaconda3/lib/python3.7/site-packages (from pandas>=0.14->quandl->qiskit-aqua==0.6.0->qiskit) (2019.1)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.3.2->qiskit) (1.12.3)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.3.2->qiskit) (0.24.0)\n",
      "Requirement already satisfied: pycparser in /home/vasilis/anaconda3/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.3.2->qiskit) (2.19)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h, J, offset = dimod.qubo_to_ising(W)\n",
    "We have to translate the Ising couplings to be suitable for solving by the QAOA routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:19.838597Z",
     "start_time": "2018-11-19T20:10:18.767740Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qiskit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-01a4c83ae926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mvp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mvp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mpauli_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPauli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qiskit' is not defined"
     ]
    }
   ],
   "source": [
    "from qiskit.quantum_info import Pauli\n",
    "from qiskit.aqua import Operator\n",
    "\n",
    "num_nodes = w.shape[0]\n",
    "pauli_list = []\n",
    "for i in range(num_nodes):\n",
    "    wp = np.zeros(num_nodes)\n",
    "    vp = np.zeros(num_nodes)\n",
    "    vp[i] = 1\n",
    "    pauli_list.append([h[i], Pauli(vp, wp)])\n",
    "    for j in range(i+1, num_nodes):\n",
    "        if w[i, j] != 0:\n",
    "            wp = np.zeros(num_nodes)\n",
    "            vp = np.zeros(num_nodes)\n",
    "            vp[i] = 1\n",
    "            vp[j] = 1\n",
    "            pauli_list.append([J[i, j], qiskit.quantum.info.Z])\n",
    "            print(vp,wp)\n",
    "            print(Pauli(vp,wp))\n",
    "ising_model = Operator(paulis=pauli_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:40.568546Z",
     "start_time": "2018-11-19T20:10:19.840830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/operator.py:200: DeprecationWarning: The `Operator` class is deprecated and will be removed after 0.6. Use the class for each representation instead, including `MatrixOperator`, `WeightedPauliOperator` and `TPBGroupedWeightedPauliOperator`\n",
      "  DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/operators/op_converter.py:92: DeprecationWarning: The `Operator` class is deprecated. Please use `WeightedPauliOperator` or `TPBGroupedWeightedPauliOperator` or `MatrixOperator` instead\n",
      "  DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/operator.py:200: DeprecationWarning: The `Operator` class is deprecated and will be removed after 0.6. Use the class for each representation instead, including `MatrixOperator`, `WeightedPauliOperator` and `TPBGroupedWeightedPauliOperator`\n",
      "  DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/operator.py:951: DeprecationWarning: The `Operator` class is deprecated and will be removed after 0.6. Use the class for each representation instead, including `MatrixOperator`, `WeightedPauliOperator` and `TPBGroupedWeightedPauliOperator`\n",
      "  DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/algorithms/adaptive/vqe/vqe.py:105: DeprecationWarning: operator_mode option is deprecated and it will be removed after 0.6. Now the operator has its own mode, no need extra info to tell the VQE.\n",
      "  \"Now the operator has its own mode, no need extra info to tell the VQE.\", DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/algorithms/adaptive/vqe/vqe.py:117: DeprecationWarning: operator should be type of BaseOperator, Operator type is deprecated and it will be removed after 0.6.\n",
      "  \"it will be removed after 0.6.\", DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/operators/op_converter.py:92: DeprecationWarning: The `Operator` class is deprecated. Please use `WeightedPauliOperator` or `TPBGroupedWeightedPauliOperator` or `MatrixOperator` instead\n",
      "  DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/operator.py:200: DeprecationWarning: The `Operator` class is deprecated and will be removed after 0.6. Use the class for each representation instead, including `MatrixOperator`, `WeightedPauliOperator` and `TPBGroupedWeightedPauliOperator`\n",
      "  DeprecationWarning)\n",
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/qiskit/aqua/operator.py:951: DeprecationWarning: The `Operator` class is deprecated and will be removed after 0.6. Use the class for each representation instead, including `MatrixOperator`, `WeightedPauliOperator` and `TPBGroupedWeightedPauliOperator`\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from qiskit.aqua import get_aer_backend, QuantumInstance\n",
    "from qiskit.aqua.algorithms import QAOA\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "p = 1\n",
    "optimizer = COBYLA()\n",
    "qaoa = QAOA(ising_model, optimizer, p, operator_mode='matrix')\n",
    "backend = get_aer_backend('statevector_simulator')\n",
    "quantum_instance = QuantumInstance(backend, shots=10)\n",
    "result = qaoa.run(quantum_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we extract the most likely solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:40.577140Z",
     "start_time": "2018-11-19T20:10:40.571807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "k = np.argmax(result['eigvecs'][0])\n",
    "print(k)\n",
    "weights = np.zeros(num_nodes)\n",
    "for i in range(num_nodes):\n",
    "    weights[i] = k % 2\n",
    "    k >>= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the weights found by QAOA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:40.597309Z",
     "start_time": "2018-11-19T20:10:40.579449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the final accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T20:10:40.614781Z",
     "start_time": "2018-11-19T20:10:40.602793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (train):  0.00\n",
      "accuracy (test):  0.00\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (train): %5.2f'%(metric(y_train, predict(models, weights, X_train))))\n",
    "print('accuracy (test): %5.2f'%(metric(y_test, predict(models, weights, X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Neven, H., Denchev, V.S., Rose, G., Macready, W.G. (2008). [Training a binary classifier with the quantum adiabatic algorithm](https://arxiv.org/abs/0811.0416). *arXiv:0811.0416*.  <a id='1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
